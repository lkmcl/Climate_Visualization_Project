{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00cae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def pull_location_file(location):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function matches an inputted city within CONUS to the associated climate file for that location. \n",
    "    The location is matched via a dictionary to the associated The file\n",
    "    pulled corresponds to the parameter input which could either be average temperature or average precipitation.\n",
    "    The file name is returned.\n",
    "    \n",
    "    Inputs:\n",
    "    location (string): structured \"City, ST\" in which the state is the two letter state abbreviation.\n",
    "    \n",
    "    parameter (string): either \"Average Temperature\" or \"Average Precipitation\"\n",
    "    \n",
    "    Returns:\n",
    "    used_filepath (string): filepath corresponding to the location of the city climate file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Load the dictionary with cities and their corresponding Cooperative Observer Identification Numbers.\n",
    "    #    This dictionary can be expanded to all cities located in the climate directory.\n",
    "    \n",
    "    city_dictionary = {'Raleigh, NC': '317074', 'Albany, NY': '300047',\n",
    "                      'Seattle, WA': '457478', 'Dallas, TX': '412243',\n",
    "                      'Salt Lake City, UT': '427578', 'Bismark, ND': '320818',\n",
    "                      'Kansas City, MO': '234379', 'Flagstaff, AZ': '023009',\n",
    "                      'Indianapolis, IN': '124260', 'Tallahassee, FL': '088756'}\n",
    "    \n",
    "    # Pull the city's ID\n",
    "    desired_ID = city_dictionary[location]\n",
    "    \n",
    "    # FI\n",
    "    filepath = glob.glob(os.getcwd() + '/CONUS_city_climate_stats/USC00'+ desired_ID +'.FLs.52j.tavg') \n",
    "    \n",
    "    used_filepath = filepath[0]\n",
    "    \n",
    "    return used_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1188f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Station Climate ID  Year January February March April   May  June  July  \\\n",
      "0          USC00023009  1904     NaN      NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1          USC00023009  1905    -159      NaN   147   417   594  1218  1688   \n",
      "2          USC00023009  1906    -470     -160    72   400   734  1138  1677   \n",
      "3          USC00023009  1907    -389      119   171   575   639  1047  1684   \n",
      "4          USC00023009  1908    -163     -158   242   488   NaN  1205  1713   \n",
      "..                 ...   ...     ...      ...   ...   ...   ...   ...   ...   \n",
      "114        USC00023009  2018      55      -12   250   756   955  1548  1852   \n",
      "115        USC00023009  2019     -58     -339   280   671   632  1278  1790   \n",
      "116        USC00023009  2020    -144        0   182   591  1053  1408  1822   \n",
      "117        USC00023009  2021    -209      -90   110   648   903  1615  1887   \n",
      "118        USC00023009  2022    -103     -136   261   631  1048  1555  1873   \n",
      "\n",
      "    August September October November December  \n",
      "0      NaN       NaN     NaN      NaN     -210  \n",
      "1     1669      1298     705       52     -540  \n",
      "2     1476      1100     611     -118     -154  \n",
      "3     1593      1240     828       90     -110  \n",
      "4     1599      1199     518       57     -232  \n",
      "..     ...       ...     ...      ...      ...  \n",
      "114   1702      1337     671       95     -159  \n",
      "115   1758      1355     590      196     -208  \n",
      "116   1867      1334     929      304     -264  \n",
      "117   1685      1419     599      372      -30  \n",
      "118   1717      1463     761      -40      NaN  \n",
      "\n",
      "[119 rows x 14 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Climate ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>January</th>\n",
       "      <th>February</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>September</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>1905</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.17</td>\n",
       "      <td>5.94</td>\n",
       "      <td>12.18</td>\n",
       "      <td>16.88</td>\n",
       "      <td>16.69</td>\n",
       "      <td>12.98</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>1906</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.34</td>\n",
       "      <td>11.38</td>\n",
       "      <td>16.77</td>\n",
       "      <td>14.76</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>1907</td>\n",
       "      <td>-3.89</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.71</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.39</td>\n",
       "      <td>10.47</td>\n",
       "      <td>16.84</td>\n",
       "      <td>15.93</td>\n",
       "      <td>12.40</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>1908</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.05</td>\n",
       "      <td>17.13</td>\n",
       "      <td>15.99</td>\n",
       "      <td>11.99</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.50</td>\n",
       "      <td>7.56</td>\n",
       "      <td>9.55</td>\n",
       "      <td>15.48</td>\n",
       "      <td>18.52</td>\n",
       "      <td>17.02</td>\n",
       "      <td>13.37</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-3.39</td>\n",
       "      <td>2.80</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.32</td>\n",
       "      <td>12.78</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.58</td>\n",
       "      <td>13.55</td>\n",
       "      <td>5.90</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>2020</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.82</td>\n",
       "      <td>5.91</td>\n",
       "      <td>10.53</td>\n",
       "      <td>14.08</td>\n",
       "      <td>18.22</td>\n",
       "      <td>18.67</td>\n",
       "      <td>13.34</td>\n",
       "      <td>9.29</td>\n",
       "      <td>3.04</td>\n",
       "      <td>-2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>2021</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.03</td>\n",
       "      <td>16.15</td>\n",
       "      <td>18.87</td>\n",
       "      <td>16.85</td>\n",
       "      <td>14.19</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.72</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>USC00023009</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>2.61</td>\n",
       "      <td>6.31</td>\n",
       "      <td>10.48</td>\n",
       "      <td>15.55</td>\n",
       "      <td>18.73</td>\n",
       "      <td>17.17</td>\n",
       "      <td>14.63</td>\n",
       "      <td>7.61</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Station Climate ID  Year  January  February  March  April    May   June  \\\n",
       "0          USC00023009  1904      NaN       NaN    NaN    NaN    NaN    NaN   \n",
       "1          USC00023009  1905    -1.59       NaN   1.47   4.17   5.94  12.18   \n",
       "2          USC00023009  1906    -4.70     -1.60   0.72   4.00   7.34  11.38   \n",
       "3          USC00023009  1907    -3.89      1.19   1.71   5.75   6.39  10.47   \n",
       "4          USC00023009  1908    -1.63     -1.58   2.42   4.88    NaN  12.05   \n",
       "..                 ...   ...      ...       ...    ...    ...    ...    ...   \n",
       "114        USC00023009  2018     0.55     -0.12   2.50   7.56   9.55  15.48   \n",
       "115        USC00023009  2019    -0.58     -3.39   2.80   6.71   6.32  12.78   \n",
       "116        USC00023009  2020    -1.44      0.00   1.82   5.91  10.53  14.08   \n",
       "117        USC00023009  2021    -2.09     -0.90   1.10   6.48   9.03  16.15   \n",
       "118        USC00023009  2022    -1.03     -1.36   2.61   6.31  10.48  15.55   \n",
       "\n",
       "      July  August  September  October  November  December  \n",
       "0      NaN     NaN        NaN      NaN       NaN     -2.10  \n",
       "1    16.88   16.69      12.98     7.05      0.52     -5.40  \n",
       "2    16.77   14.76      11.00     6.11     -1.18     -1.54  \n",
       "3    16.84   15.93      12.40     8.28      0.90     -1.10  \n",
       "4    17.13   15.99      11.99     5.18      0.57     -2.32  \n",
       "..     ...     ...        ...      ...       ...       ...  \n",
       "114  18.52   17.02      13.37     6.71      0.95     -1.59  \n",
       "115  17.90   17.58      13.55     5.90      1.96     -2.08  \n",
       "116  18.22   18.67      13.34     9.29      3.04     -2.64  \n",
       "117  18.87   16.85      14.19     5.99      3.72     -0.30  \n",
       "118  18.73   17.17      14.63     7.61     -0.40       NaN  \n",
       "\n",
       "[119 rows x 14 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "#rom pull_location_file import pull_location_file\n",
    "\n",
    "def parse_climate_data(used_filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes a city climate data file that includes and format into a Pandas dataframe.\n",
    "    Values of -9999 are interpreted as missing values. Each datapoint is scaled accordingly.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (String) - The filename of the city climate file to be parsed.\n",
    "    Returns:\n",
    "        (df_city) - A DataFrame containing all of the parsed and adjusted data.\n",
    "    \"\"\"\n",
    "    \n",
    "    headings = ['Station Climate ID', 'Year', 'January', 'February', 'March', 'April',\n",
    "                                 'May', 'June', 'July', 'August', 'September',\n",
    "                                 'October', 'November', 'December']\n",
    "    \n",
    "    # We need to specify the widths as the default colspec 'infer' does not correctly pick up rarely seen missing data values. \n",
    "\n",
    "    widths = [11, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "\n",
    "    df = pd.read_fwf(used_filename, names=headings, header=None, widths=widths, na_values=[-9999])\n",
    "    \n",
    "    df[['January','February','March','April','May','June','July','August',\n",
    "       'September','October','November','December']]= df[['January','February','March','April','May','June','July','August',\n",
    "       'September','October','November','December']].replace(regex=['a','b','c','d','e','f','g','h','i','E','X',\n",
    "                                                                   'D','I','L','M','O','S','W','A','M','Q'], value=\"\")\n",
    "    \n",
    "    df[['January','February','March','April','May','June','July','August',\n",
    "       'September','October','November','December']]= df[['January','February','March','April','May','June','July','August',\n",
    "       'September','October','November','December']].astype(float)/100\n",
    "\n",
    "    return df\n",
    "\n",
    "used_filepath = pull_location_file('Flagstaff, AZ')\n",
    "parse_climate_data(used_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a0c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479478b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
